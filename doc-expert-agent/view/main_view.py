from model.answer import Answer
from model.input import Input
import streamlit as st

from typing import List

from logger import get_logger

logger = get_logger(__name__)

class MainView:
    """Classe respons√°vel pela interface de usu√°rio usando Streamlit."""

    @staticmethod
    def set_view(callback):
        logger.info("Configurando View")
        
        with st.container():
            
            prompt_type_option = None

            connection_type_option = MainView.get_connection_type()

            if connection_type_option == "conexao-simples-llm":
                prompt_type_option, pergunta = MainView.render_conexao_simples_llm()
            
            elif connection_type_option in ["conexao-llm-complete-memory", "conexao-llm-summary-memory"]:
                pergunta = MainView.render_conexao_memory_llm()
                
            elif connection_type_option in ["conexao-com-tool", "conexao-com-tool-react"]:
                pergunta = MainView.render_conexao_tools_llm()
            
            with st.form(key="meu_formulario"):
                # Campo de pergunta
                question_input = st.text_area(
                    "Digite sua pergunta:",
                    value=pergunta,
                    height=60,
                )
                
                # Bot√£o de envio
                col1, col2, col3 = st.columns([1, 2, 1])
                with col1:
                    submit = st.form_submit_button(
                        "Enviar Pergunta",
                        use_container_width=True
                    )

            if submit:
                if question_input and question_input.strip():
                    input = Input(
                        question=question_input,
                        connection_type=connection_type_option,
                        prompt_type=prompt_type_option
                    )
                    callback(input)
                else:
                    st.error("‚ùå Por favor, insira uma pergunta antes de enviar.")

    def get_connection_type():
        """Seletor de tipo de conex√£o."""
        return st.selectbox(
            "Escolha o tipo de conex√£o:",
            [
                "conexao-simples-llm", 
                "conexao-llm-complete-memory",
                "conexao-llm-summary-memory",
                "conexao-com-tool", 
                "conexao-com-tool-react", 
            ],
            format_func=lambda x: {
                "conexao-simples-llm": "Conex√£o Simples",
                "conexao-llm-complete-memory": "Mem√≥ria Completa",
                "conexao-llm-summary-memory": "Mem√≥ria Resumida",
                "conexao-com-tool": "Com Tools",
                "conexao-com-tool-react": "ReAct"
            }.get(x, x)
        )

    @staticmethod
    def render_conexao_simples_llm():
        """Renderiza interface para conex√£o simples."""

        prompt_type_option = st.selectbox(
            "Tipo de Prompt:",
            [   
                "ZERO_SHOT_PROMPT", 
                "FEW_SHOT_PROMPT", 
                "CHAIN_OF_THOUGHT", 
                "DEFINITION_EXEMPLIFICATION",
                "STYLE_SPECIFIC_PROMPTING", 
                "LENGHT_LIMITATION_PROMPTING", 
                "STEP_BY_STEP_INSTRUCTION_PROMPTING",
            ],
            format_func=lambda x: {
                "ZERO_SHOT_PROMPT": "Zero Shot",
                "FEW_SHOT_PROMPT": "Few Shot",
                "CHAIN_OF_THOUGHT": "Chain of Thought",
                "DEFINITION_EXEMPLIFICATION": "Defini√ß√£o + Exemplo",
                "STYLE_SPECIFIC_PROMPTING": "Estilo Espec√≠fico",
                "LENGHT_LIMITATION_PROMPTING": "Limita√ß√£o de Tamanho",
                "STEP_BY_STEP_INSTRUCTION_PROMPTING": "Passo a Passo"
            }.get(x, x)
        )

        st.info("**Observa√ß√£o:**\n- **Documento anexado:** TCC")
        pergunta = "quem escreveu o trabalho?"
        return prompt_type_option, pergunta

    @staticmethod
    def render_conexao_memory_llm():
        """Renderiza interface para conex√£o com mem√≥ria."""
        st.info("**Observa√ß√£o:**\n- **Mem√≥ria Completa:** Mant√©m todo o hist√≥rico da conversa\n- **Mem√≥ria Resumida:** Cria resumos autom√°ticos da conversa \n- **Documento anexado:** Livro do Harry Potter e a Pedra Filosofal, cap√≠tulo 1")
        pergunta = "Sempre que eu perguntar qual o meu nome, voce responde: Thales. Resume o livro em 15 palavras."
        return pergunta

    @staticmethod
    def render_conexao_tools_llm():
        """Renderiza interface para conex√£o com tools."""        
        st.info("**Observa√ß√£o:**\n- **celulares_atualizados():** Retorna quantidade de celulares no Brasil\n- O sistema detecta automaticamente quando usar ferramentas \n- **Documento anexado:** TCC")
        pergunta = "Quantos celulares o app pode rodar em 2025?"
        return pergunta


    @staticmethod
    def update_view_with_chunks(answers: List[Answer]):
        """Atualiza a view com os chunks recuperados."""
        st.subheader("üß© Chunks Recuperados")
        
        if not answers:
            st.warning("‚ö†Ô∏è Nenhum chunk foi encontrado para a pergunta.")
            return
        
        for i, answer in enumerate(answers, 1):
            with st.expander(f"üìÑ Chunk {i}", expanded=False):
                st.write("**Conte√∫do:**")
                st.write(answer.content)
                
                if answer.metadata:
                    st.write("**Metadados:**")
                    st.write(answer.metadata)

    @staticmethod
    def update_view_with_result(result: str):
        """Atualiza a view com o resultado final."""
        st.subheader("‚úÖ Resposta Final")
        st.write(result)

    @staticmethod
    def update_view_with_evaluate(evaluate: str):
        """Atualiza a view com a avalia√ß√£o."""
        st.subheader("üîç Avalia√ß√£o de Qualidade")
        st.write(evaluate)

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 20 0 (offset 0)\n",
      "Ignoring wrong pointing object 22 0 (offset 0)\n",
      "Ignoring wrong pointing object 42 0 (offset 0)\n",
      "Ignoring wrong pointing object 50 0 (offset 0)\n",
      "Ignoring wrong pointing object 52 0 (offset 0)\n",
      "Ignoring wrong pointing object 54 0 (offset 0)\n",
      "Ignoring wrong pointing object 56 0 (offset 0)\n",
      "Ignoring wrong pointing object 58 0 (offset 0)\n",
      "Ignoring wrong pointing object 70 0 (offset 0)\n",
      "Ignoring wrong pointing object 72 0 (offset 0)\n",
      "Ignoring wrong pointing object 89 0 (offset 0)\n",
      "Ignoring wrong pointing object 91 0 (offset 0)\n",
      "Ignoring wrong pointing object 103 0 (offset 0)\n",
      "Ignoring wrong pointing object 108 0 (offset 0)\n",
      "Ignoring wrong pointing object 149 0 (offset 0)\n",
      "Ignoring wrong pointing object 155 0 (offset 0)\n",
      "Ignoring wrong pointing object 158 0 (offset 0)\n",
      "Ignoring wrong pointing object 160 0 (offset 0)\n",
      "Ignoring wrong pointing object 163 0 (offset 0)\n",
      "Ignoring wrong pointing object 165 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'O que é Hugging Face e como faço para acessá-lo?',\n",
       " 'result': 'Hugging Face é uma empresa que desenvolve tecnologias de inteligência artificial, especialmente em processamento de linguagem natural (NLP). Eles são conhecidos por suas bibliotecas e modelos de aprendizado de máquina de código aberto, como o Transformers, que permite que desenvolvedores e pesquisadores utilizem modelos pré-treinados para diversas tarefas, como tradução, geração de texto, entre outros.\\n\\nPara acessar o Hugging Face, você pode visitar o site oficial em [huggingface.co](https://huggingface.co). A partir daí, você pode explorar a biblioteca, baixar modelos, acessar documentação e tutoriais para começar a usar os modelos em seus projetos. Além disso, você pode encontrar informações sobre como integrar esses modelos em aplicações, seja localmente ou na nuvem.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "\n",
    "from langchain_community.document_loaders.pdf import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.chains.retrieval_qa.base import RetrievalQA\n",
    "\n",
    "caminhos = [\n",
    "    \"../files/apostila.pdf\",\n",
    "    \"../files/LLM.pdf\",\n",
    "    ]\n",
    "\n",
    "paginas = []\n",
    "for caminho in caminhos:\n",
    "    loader = PyPDFLoader(caminho)\n",
    "    paginas.extend(loader.load())\n",
    "\n",
    "recur_split = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "documents = recur_split.split_documents(paginas)\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    doc.metadata['source'] = doc.metadata['source'].replace('arquivos/', '')\n",
    "    doc.metadata['doc_id'] = i\n",
    "\n",
    "diretorio = '../files/arquivos/chat_retrieval_db'\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embeddings_model,\n",
    "    persist_directory=diretorio\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'),\n",
    ")\n",
    "\n",
    "pergunta = \"O que é Hugging Face e como faço para acessá-lo?\"\n",
    "chat_chain.invoke({\"query\": pergunta})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma plataforma que oferece uma variedade de modelos de código aberto para processamento de linguagem natural, incluindo modelos transformadores. Você pode acessá-lo através do site da Hugging Face, onde pode explorar e baixar modelos, além de encontrar documentação e exemplos de uso. Para começar a usar os modelos, é recomendável ter alguma experiência em Python e seguir as instruções fornecidas na plataforma.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "chain_prompt = PromptTemplate.from_template(\n",
    "\"\"\"Utilize o contexto fornecido para responder a pergunta ao final. \n",
    "Se você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\n",
    "Utilize três frases no máximo, mantenha a resposta concisa.\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    "    chain_type_kwargs={\"prompt\":chain_prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados', metadata={'doc_id': 75, 'page': 6, 'source': '../files/LLM.pdf'}),\n",
       " Document(page_content='. Se suas mãos já estão tremendo de emoção e você já tem algum conhecimento prático de Python e Databricks, forneceremos alguns ótimos exemplos com código de exemplo que podem ajudar você a começar a trabalhar com LLMs imediatamente.', metadata={'doc_id': 79, 'page': 7, 'source': '../files/LLM.pdf'}),\n",
       " Document(page_content='E-BOOK Um guia compacto sobre Large Language Models (LLM)', metadata={'doc_id': 55, 'page': 0, 'source': '../files/LLM.pdf'}),\n",
       " Document(page_content='Sobre a Databricks A Databricks é a empresa de dados e IA. Mais de 9.000 organizações em todo o mundo, incluindo a Comcast, Condé Nast e mais de 50% da Fortune 500, contam com a Plataforma Databricks Lakehouse para unificar seus dados, análises e IA. A Databricks tem sede em São Francisco, com escritórios em todo o mundo. Fundada pelos criadores originais do Apache Spark™, Delta Lake e MLflow, a Databricks tem como missão ajudar as equipes de dados a resolver os problemas mais difíceis do mundo. Para saber mais, siga a Databricks no Twitter, LinkedIn e Facebook.                 EXPERIMENTE GRÁTIS    Entre em contato conosco para ver uma demonstração: databricks.com/contact                     © Databricks 2023. Todos os direitos reservados. Apache, Apache Spark, Spark e o logotipo Spark são marcas registradas da Apache Software Foundation. Política de privacidade | Termos de uso', metadata={'doc_id': 80, 'page': 8, 'source': '../files/LLM.pdf'})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"O que é Hugging Face e como faço para acessá-lo?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"O que é Hugging Face e como faço para acessá-lo?\",\n",
      "  \"context\": \"Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados\\n\\n. Se suas mãos já estão tremendo de emoção e você já tem algum conhecimento prático de Python e Databricks, forneceremos alguns ótimos exemplos com código de exemplo que podem ajudar você a começar a trabalhar com LLMs imediatamente.\\n\\nE-BOOK Um guia compacto sobre Large Language Models (LLM)\\n\\nSobre a Databricks A Databricks é a empresa de dados e IA. Mais de 9.000 organizações em todo o mundo, incluindo a Comcast, Condé Nast e mais de 50% da Fortune 500, contam com a Plataforma Databricks Lakehouse para unificar seus dados, análises e IA. A Databricks tem sede em São Francisco, com escritórios em todo o mundo. Fundada pelos criadores originais do Apache Spark™, Delta Lake e MLflow, a Databricks tem como missão ajudar as equipes de dados a resolver os problemas mais difíceis do mundo. Para saber mais, siga a Databricks no Twitter, LinkedIn e Facebook.                 EXPERIMENTE GRÁTIS    Entre em contato conosco para ver uma demonstração: databricks.com/contact                     © Databricks 2023. Todos os direitos reservados. Apache, Apache Spark, Spark e o logotipo Spark são marcas registradas da Apache Software Foundation. Política de privacidade | Termos de uso\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: Utilize o contexto fornecido para responder a pergunta ao final. \\nSe você não sabe a resposta, apenas diga que não sabe e não invente uma resposta.\\nUtilize três frases no máximo, mantenha a resposta concisa.\\n\\nContexto: Atualmente, requer um pouco mais de esforço para pegar um modelo de código aberto e começar a usá-lo, mas o progresso está ocorrendo muito rapidamente para torná-los mais acessíveis aos usuários. Na Databricks, por exemplo, fizemos melhorias em frameworks de código aberto como o MLflow para tornar muito fácil para alguém com um pouco de experiência em Python pegar qualquer modelo transformador da Hugging Face e usá-lo como um objeto Python. Muitas vezes, você pode encontrar um modelo de código aberto que resolve seu problema específico e que é várias ordens de grandeza menor que o ChatGPT, permitindo que você traga o modelo para seu ambiente e hospede-o você mesmo. Isso significa que você pode manter os dados sob seu controle para preocupações com privacidade e governança, além de gerenciar seus custos. Outra grande vantagem de usar modelos de código aberto é a capacidade de ajustá-los aos seus próprios dados\\n\\n. Se suas mãos já estão tremendo de emoção e você já tem algum conhecimento prático de Python e Databricks, forneceremos alguns ótimos exemplos com código de exemplo que podem ajudar você a começar a trabalhar com LLMs imediatamente.\\n\\nE-BOOK Um guia compacto sobre Large Language Models (LLM)\\n\\nSobre a Databricks A Databricks é a empresa de dados e IA. Mais de 9.000 organizações em todo o mundo, incluindo a Comcast, Condé Nast e mais de 50% da Fortune 500, contam com a Plataforma Databricks Lakehouse para unificar seus dados, análises e IA. A Databricks tem sede em São Francisco, com escritórios em todo o mundo. Fundada pelos criadores originais do Apache Spark™, Delta Lake e MLflow, a Databricks tem como missão ajudar as equipes de dados a resolver os problemas mais difíceis do mundo. Para saber mais, siga a Databricks no Twitter, LinkedIn e Facebook.                 EXPERIMENTE GRÁTIS    Entre em contato conosco para ver uma demonstração: databricks.com/contact                     © Databricks 2023. Todos os direitos reservados. Apache, Apache Spark, Spark e o logotipo Spark são marcas registradas da Apache Software Foundation. Política de privacidade | Termos de uso\\n\\nPergunta: O que é Hugging Face e como faço para acessá-lo?\\n\\nResposta:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain > llm:ChatOpenAI] [1.27s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessá-lo através do seu site, onde pode encontrar modelos e documentação para utilizá-los em seus projetos. Para começar, é recomendável ter um pouco de experiência em Python.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessá-lo através do seu site, onde pode encontrar modelos e documentação para utilizá-los em seus projetos. Para começar, é recomendável ter um pouco de experiência em Python.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 64,\n",
      "                \"prompt_tokens\": 536,\n",
      "                \"total_tokens\": 600,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-4o-mini\",\n",
      "              \"system_fingerprint\": \"fp_34a54ae93c\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-a4b108c1-43c3-4cb5-8450-c3c634be8ab3-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 64,\n",
      "      \"prompt_tokens\": 536,\n",
      "      \"total_tokens\": 600,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-4o-mini\",\n",
      "    \"system_fingerprint\": \"fp_34a54ae93c\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain > chain:LLMChain] [1.28s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessá-lo através do seu site, onde pode encontrar modelos e documentação para utilizá-los em seus projetos. Para começar, é recomendável ter um pouco de experiência em Python.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA > chain:StuffDocumentsChain] [1.29s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"Hugging Face é uma plataforma que oferece uma vasta coleção de modelos de aprendizado de máquina, especialmente para processamento de linguagem natural. Você pode acessá-lo através do seu site, onde pode encontrar modelos e documentação para utilizá-los em seus projetos. Para começar, é recomendável ter um pouco de experiência em Python.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RetrievalQA] [1.84s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "\n",
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face é uma empresa e uma comunidade de código aberto que desenvolve e mantém a biblioteca Transformers, amplamente utilizada para tarefas de processamento de linguagem natural (NLP), especialmente em relação a Modelos de Linguagem de Grande Escala (LLMs). Essa biblioteca facilita o acesso a modelos pré-treinados, permitindo a implementação de soluções que envolvem texto, como chatbots, tradução automática e análise de sentimentos.\n",
      "\n",
      "Para acessar e começar a usar o Hugging Face, siga estas etapas:\n",
      "\n",
      "1. **Visite o site:** Acesse o site oficial da Hugging Face em [huggingface.co](https://huggingface.co).\n",
      "\n",
      "2. **Explore a biblioteca:** Na seção \"Models\" do site, você poderá explorar uma ampla gama de modelos disponíveis. É possível filtrar por tarefa, tipo de modelo e outras características.\n",
      "\n",
      "3. **Instale a biblioteca:** Para usar os modelos em seu próprio código, instale a biblioteca Transformers utilizando o gerenciador de pacotes pip. Execute o seguinte comando em seu terminal:\n",
      "   ```bash\n",
      "   pip install transformers\n",
      "   ```\n",
      "\n",
      "4. **Utilize os modelos em Python:** Após instalar a biblioteca, você pode carregar e usar os modelos em seu código Python. Aqui está um exemplo básico de como usar um modelo de linguagem:\n",
      "\n",
      "   ```python\n",
      "   from transformers import pipeline\n",
      "\n",
      "   # Cria um pipeline para geração de texto\n",
      "   generator = pipeline('text-generation', model='gpt2')\n",
      "\n",
      "   # Gera texto\n",
      "   result = generator(\"Aqui está um exemplo de\", max_length=50)\n",
      "   print(result)\n",
      "   ```\n",
      "\n",
      "5. **Integração com Databricks:** Se você estiver usando a plataforma Databricks, que é amplamente adotada por mais de 9.000 organizações em todo o mundo para unificar dados, análises e IA, você pode criar um novo notebook e executar o código Python acima diretamente em uma célula. A biblioteca Hugging Face funciona bem em ambientes de notebook, permitindo que você experimente rapidamente diferentes modelos e gerações de texto.\n",
      "\n",
      "6. **Ajuste os modelos:** Além disso, você pode ajustar os modelos aos seus dados específicos, personalizando seu desempenho. A Hugging Face fornece documentação e tutoriais que podem auxiliá-lo nesse processo.\n",
      "\n",
      "Esses passos devem ajudá-lo a acessar e começar a usar o Hugging Face de forma eficaz, especialmente em conjunto com a Databricks, que oferece uma plataforma robusta para lidar com dados e IA.\n"
     ]
    }
   ],
   "source": [
    "chat_chain = RetrievalQA.from_chain_type(\n",
    "    llm=chat,\n",
    "    retriever=vectordb.as_retriever(search_type='mmr'),\n",
    "    chain_type='refine'\n",
    ")\n",
    "\n",
    "pergunta = 'O que é Hugging Face e como faço para acessá-lo?'\n",
    "resposta = chat_chain.invoke({'query': pergunta})\n",
    "print(resposta['result'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
